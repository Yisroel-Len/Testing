{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6799e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:56:49.842108Z",
     "start_time": "2023-08-08T14:56:49.838872Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc \n",
    "import time\n",
    "import datetime\n",
    "import sqlite3\n",
    "from pandas.tseries.offsets import DateOffset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af8717",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:56:49.848219Z",
     "start_time": "2023-08-08T14:56:49.844107Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "path = \"..\\..\\InSyncConnection\\Code\\clinical_log.txt\"\n",
    "logging.basicConfig(filename=path,\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s,%(msecs)d,%(name)s,%(levelname)s,%(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.DEBUG)\n",
    "logger = logging.getLogger(\"NOMS-Survey Completion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4456cbdd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## DB Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34cb8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:56:49.860051Z",
     "start_time": "2023-08-08T14:56:49.850222Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('../../InSyncConnection/Database/InSyncClinical.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# # # printing all table names\n",
    "# sql_query = \"\"\"SELECT name FROM sqlite_master\n",
    "#      WHERE type='table';\"\"\"\n",
    "\n",
    "# cursor.execute(sql_query)\n",
    "# print(cursor.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c666fdfd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Encounter Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcff2c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:02.455928Z",
     "start_time": "2023-08-08T14:56:49.863048Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Select all patients from EcounterSummary Table\n",
    "    testPatients = '''\n",
    "    SELECT\n",
    "        PatientId\n",
    "    FROM \n",
    "        emr_PatientDetails\n",
    "    WHERE \n",
    "        LOWER(FirstName) LIKE '%test%'\n",
    "        OR LOWER(LastName) LIKE '%test%'\n",
    "        OR LOWER(FirstName) LIKE '%patient%'\n",
    "        OR LOWER(LastName) LIKE '%patient%'\n",
    "        or CAST(MRNNumber AS INTEGER) < 55\n",
    "    '''\n",
    "    sql=f'''\n",
    "    SELECT \n",
    "        PatientId as PatientID,\n",
    "        VisitDateTime as EncounterDate\n",
    "    FROM \n",
    "        tblEncounterSummary\n",
    "        LEFT JOIN tblENcounterType ON (tblEncounterSummary.EncounterTypeId=tblENcounterType.EncounterTypeId)\n",
    "    WHERE \n",
    "        IsBillable = \"TRUE\"\n",
    "        AND PatientID NOT IN ({testPatients})\n",
    "    ORDER BY \n",
    "        PatientID\n",
    "    '''\n",
    "    encounter_df = pd.read_sql(sql, conn)\n",
    "    encounter_df['EncounterDate'] = pd.to_datetime(encounter_df['EncounterDate'])\n",
    "    \n",
    "    #filter out encounters before 3/1 and keep the first encounter date\n",
    "    encounter_filter = encounter_df['EncounterDate'] >= '2023-03-01'\n",
    "    filtered_dates = encounter_df[encounter_filter].copy()\n",
    "    filtered_dates.sort_values(by=['PatientID', 'EncounterDate'], inplace=True)\n",
    "    encounter_df = filtered_dates.drop_duplicates(subset=\"PatientID\", keep='first').copy()\n",
    "    \n",
    "    # get encounter time by hour\n",
    "    encounter_df['Hour'] = encounter_df[\"EncounterDate\"].dt.floor('h')\n",
    "    \n",
    "    # needed for filtering out transfer patients\n",
    "    encounter_dictionary = dict(zip(encounter_df.PatientID, encounter_df.EncounterDate))\n",
    "    \n",
    "    logger.info(f\"Successfully queried tblEncounterSummary.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to query tblEncounterSummary.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "encounter_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013b00e2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### PatientDetails Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c72803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:02.546023Z",
     "start_time": "2023-08-08T14:57:02.456928Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Select all patients\n",
    "    sql= f'''\n",
    "    SELECT \n",
    "        DISTINCT (PatientID) AS PatientID,\n",
    "        FirstName,\n",
    "        LastName,\n",
    "        DOB,\n",
    "        MRNNumber,\n",
    "        PhoneNo AS Phone\n",
    "    FROM \n",
    "        emr_PatientDetails\n",
    "    WHERE\n",
    "        PatientID NOT IN ({testPatients})\n",
    "    ORDER BY \n",
    "        PatientID\n",
    "    '''\n",
    "    patient_details_df = pd.read_sql(sql, conn)\n",
    "    \n",
    "    # filter out MRN != XXX2\n",
    "    MRN_filter = patient_details_df['MRNNumber'].map(lambda value: True if value[-1] == \"2\" else False)\n",
    "    patient_details_df = patient_details_df[MRN_filter].copy()\n",
    "    \n",
    "    # filter out test patients\n",
    "    test_filter = (patient_details_df['LastName'] != \"Test\") & (patient_details_df[\"FirstName\"] != \"Test\")\n",
    "    patient_details_df = patient_details_df[test_filter].copy()\n",
    "    \n",
    "    logger.info(f\"Successfully queried emr_PatientDetails.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to query emr_PatientDetails.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "\n",
    "patient_details_df[patient_details_df['PatientID'].duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054039c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Discharged Query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69c9c5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:02.597526Z",
     "start_time": "2023-08-08T14:57:02.548020Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Select all patients\n",
    "    sql = f'''\n",
    "    SELECT \n",
    "        PatientID,\n",
    "        finalEncounterDate AS 'Final Encounter',\n",
    "        is_ActiveInInSync,\n",
    "        is_lastEncounterDischarge\n",
    "    FROM \n",
    "        ptPatient_Activity\n",
    "    WHERE\n",
    "        PatientID NOT IN ({testPatients})\n",
    "    '''\n",
    "    disharge_df = pd.read_sql(sql, conn)\n",
    "    \n",
    "    # filter out active patients\n",
    "    discharged_patients_mask = (disharge_df['is_ActiveInInSync'] == 0) | (disharge_df['is_lastEncounterDischarge'] == 1)\n",
    "    discharged_patients_df = disharge_df[discharged_patients_mask].copy()\n",
    "    \n",
    "    # create discharge status\n",
    "    discharged_patients_df['Status'] = \"Discharged\"\n",
    "    \n",
    "    discharged_patients_df.drop(columns=['is_ActiveInInSync','is_lastEncounterDischarge'],\n",
    "                                axis=1,\n",
    "                                inplace=True)\n",
    "    discharged_patients_df['Final Encounter'] = pd.to_datetime(discharged_patients_df['Final Encounter'])\n",
    "    \n",
    "    logger.info(f\"Successfully queried ptPatient_Activity.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to query ptPatient_Activity.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "discharged_patients_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9464e54c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### NOMS Query "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca083be7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Baseline NOMS Taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be402ae5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:02.681096Z",
     "start_time": "2023-08-08T14:57:02.598526Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sql=f'''\n",
    "    SELECT \n",
    "        PatientID,\n",
    "        CreatedOn,\n",
    "        StatusDesc AS 'Baseline NOMS'\n",
    "    FROM \n",
    "        tblNOMS_AllAssessments\n",
    "    WHERE \n",
    "        AssessmentKey LIKE '%Baseline%'\n",
    "        AND (StatusDesc LIKE \"%Entered%\"\n",
    "        OR StatusDesc LIKE \"%Completed%\")\n",
    "        AND\n",
    "        PatientID NOT IN ({testPatients})\n",
    "    ORDER BY\n",
    "        PatientID\n",
    "    '''\n",
    "    df = pd.read_sql(sql, conn)\n",
    "    df['CreatedOn'] = pd.to_datetime(df['CreatedOn']).dt.date\n",
    "    \n",
    "    # filter before march\n",
    "    march_mask = datetime.date(2023,3,1)\n",
    "    baseline_df = df[df['CreatedOn'] >= march_mask].copy()\n",
    "    \n",
    "    # Prettify data for mergers later\n",
    "    baseline_df['Baseline NOMS'] = baseline_df['Baseline NOMS'].map(lambda status: True if str(status) in ['Completed', \"Entered Into SPARS\"] else False)\n",
    "    \n",
    "    logger.info(f\"Successfully queried tblNOMS_AllAssessments for Baselines.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to query tblNOMS_AllAssessments for Baselines.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841d150e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Reassessment NOMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403a0457",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:02.805800Z",
     "start_time": "2023-08-08T14:57:02.685089Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sql=f'''\n",
    "    SELECT \n",
    "        PatientID,\n",
    "        CreatedOn\n",
    "    FROM \n",
    "        tblNOMS_AllAssessments\n",
    "    WHERE \n",
    "        AssessmentKey LIKE 'Reassessment%'\n",
    "        AND (StatusDesc LIKE \"%Entered%\"\n",
    "        OR StatusDesc LIKE \"%Completed%\")\n",
    "        AND\n",
    "        PatientID NOT IN ({testPatients})\n",
    "    ORDER BY\n",
    "        PatientID\n",
    "    '''\n",
    "    df = pd.read_sql(sql, conn)\n",
    "    df['CreatedOn'] = pd.to_datetime(df['CreatedOn']).dt.date\n",
    "    \n",
    "    # filter before march\n",
    "    march_mask = datetime.date(2023,3,1)\n",
    "    reassessment_df = df[df['CreatedOn'] >= march_mask]\n",
    "    \n",
    "#     # find transfer patients\n",
    "#     transfer_patients=[]\n",
    "#     for patient in reassessment_df['PatientID']:\n",
    "#         if False != encounter_dictionary.get(patient, False):\n",
    "#             transfer_patients.append(patient)\n",
    "            \n",
    "#     # remove transfers if reassessment is before 6 months\n",
    "#     earliest_reassessment_date = datetime.date(2023,8,1)\n",
    "#     for patient in transfer_patients:\n",
    "#         first_encounter = encounter_dictionary.get(patient)\n",
    "#     #     incremented_first_encounter = first_encounter + np.timedelta64(6, 'M')\n",
    "#         reassmessnent_date = df[df['PatientID'] == patient]['CreatedOn']\n",
    "#         print(reassmessnent_date)\n",
    "#         if (reassmessnent_date.values > earliest_reassessment_date) == False:\n",
    "#             reassessment_df = reassessment_df[reassessment_df['PatientID'] != patient].copy()\n",
    "    \n",
    "    # Prettify data for megers later\n",
    "    reassessment_df = reassessment_df[['PatientID']]\n",
    "    reassessment_df['6 Month Reassessment NOMS'] = True\n",
    "    \n",
    "    logger.info(f\"Successfully queried tblNOMS_AllAssessments for Reassessments.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to query tblNOMS_AllAssessments for Reassessments.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a51c1b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Discharge NOMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a987fc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:02.840629Z",
     "start_time": "2023-08-08T14:57:02.807812Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sql=f'''\n",
    "    SELECT \n",
    "        DISTINCT (PatientID),\n",
    "        CreatedOn AS 'Discharge Date',\n",
    "        AssessmentKey AS 'Discharged'\n",
    "    FROM \n",
    "        tblNOMS_AllAssessments\n",
    "    WHERE \n",
    "        Discharged LIKE '%Discharge%'\n",
    "        AND (StatusDesc LIKE \"%Entered%\"\n",
    "        OR StatusDesc LIKE \"%Completed%\")\n",
    "        AND\n",
    "        PatientID NOT IN ({testPatients})\n",
    "    ORDER BY\n",
    "        PatientID\n",
    "    '''\n",
    "    df = pd.read_sql(sql, conn)\n",
    "    df['Discharge Date'] = pd.to_datetime(df['Discharge Date']).dt.date\n",
    "    \n",
    "    # filter before march\n",
    "    march_mask = datetime.date(2023,3,1)\n",
    "    discharge_df = df[df['Discharge Date'] >= march_mask]\n",
    "    \n",
    "    \n",
    "    # Prettify data for megers later\n",
    "    discharge_df = discharge_df[['PatientID']]\n",
    "    discharge_df.drop_duplicates(inplace=True)\n",
    "    discharge_df['Discharge NOMS'] = True\n",
    "\n",
    "    logger.info(f\"Successfully queried tblNOMS_AllAssessments for Discharges.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to query tblNOMS_AllAssessments for Discharges.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "    \n",
    "discharge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af0cd6f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### NOMS Refusals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1769b8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:02.876271Z",
     "start_time": "2023-08-08T14:57:02.842641Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sql=f'''\n",
    "    SELECT \n",
    "        PatientID,\n",
    "        InterviewConductedNoID AS Reason\n",
    "    FROM \n",
    "        tblNOMS_AllAssessments\n",
    "    WHERE \n",
    "        AssessmentKey LIKE 'Base%'      AND\n",
    "        InterviewConductedID LIKE '%0%' AND\n",
    "        PatientID NOT IN ({testPatients})\n",
    "    '''\n",
    "    refused_df = pd.read_sql(sql, conn)\n",
    "    refused_df['Consent'] = 'No'\n",
    "    # fill in blank reasons with 'None Given'\n",
    "    refused_df = refused_df.replace(r'^\\s*$', 'None Given', regex=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    refused_df = refused_df[['PatientID',\n",
    "                             'Consent',\n",
    "                             'Reason']]\n",
    "    \n",
    "    logger.info(f\"Successfully queried tblNOMS_AllAssessments for Baseline Refusals.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to query tblNOMS_AllAssessments for Baseline Refusals.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "refused_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9c6880",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### NOMS Consents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6ccbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:02.909577Z",
     "start_time": "2023-08-08T14:57:02.877280Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sql=f'''\n",
    "    SELECT \n",
    "        PatientID\n",
    "    FROM \n",
    "        tblNOMS_AllAssessments\n",
    "    WHERE \n",
    "        AssessmentKey LIKE 'Base%'      AND\n",
    "        InterviewConductedID LIKE '%1%' AND\n",
    "        PatientID NOT IN ({testPatients})\n",
    "    '''\n",
    "    agreed_df = pd.read_sql(sql, conn)\n",
    "    agreed_df\n",
    "    # add Consent\n",
    "    agreed_df[\"Consent\"] = 'Yes'\n",
    "    \n",
    "    logger.info(f\"Successfully queried tblNOMS_AllAssessments for Baseline Consents.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to query tblNOMS_AllAssessments for Baseline Consents.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "agreed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd6b53c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Append Consent dfs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11066b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:02.916065Z",
     "start_time": "2023-08-08T14:57:02.910579Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "consent_df = pd.concat([refused_df, agreed_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578afc89",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Entered into Spars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617cc29b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065c5aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:02.945881Z",
     "start_time": "2023-08-08T14:57:02.919062Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sql=f'''\n",
    "    SELECT \n",
    "        PatientID,\n",
    "        StatusDesc AS 'Baseline SPARS'\n",
    "    FROM \n",
    "        tblNOMSAssessmentDetails\n",
    "    WHERE\n",
    "        PatientID NOT IN ({testPatients})\n",
    "    ORDER BY\n",
    "        PatientID\n",
    "    '''\n",
    "    baseline_SPARS = pd.read_sql(sql,conn)\n",
    "        \n",
    "    logger.info(f\"Successfully queried tblNOMSAssessmentDetails for Baselines entered to SPARS.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to query tblNOMSAssessmentDetails for Baselines entered to SPARS.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c51bf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Reassessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d9b928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:02.972668Z",
     "start_time": "2023-08-08T14:57:02.947152Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sql=f'''\n",
    "    SELECT \n",
    "        PatientID,\n",
    "        StatusDesc AS 'Reassessment SPARS'\n",
    "    FROM \n",
    "        tblNOMSReAssessmentDetails\n",
    "    WHERE\n",
    "        PatientID NOT IN ({testPatients})\n",
    "    ORDER BY\n",
    "        PatientID\n",
    "    '''\n",
    "    reassessment_SPARS = pd.read_sql(sql,conn)\n",
    "    \n",
    "    logger.info(f\"Successfully queried tblNOMSAssessmentDetails for Reassessments entered to SPARS.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to query tblNOMSAssessmentDetails for Reassessments entered to SPARS.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2506b693",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "#### Discharges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d8e525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.004278Z",
     "start_time": "2023-08-08T14:57:02.974013Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    sql=f'''\n",
    "    SELECT \n",
    "        PatientID,\n",
    "        StatusDesc AS 'Discharge SPARS'\n",
    "    FROM \n",
    "        tblNOMSDischargeDetails\n",
    "    WHERE\n",
    "        PatientID NOT IN ({testPatients})\n",
    "    ORDER BY\n",
    "        PatientID\n",
    "    '''\n",
    "    discharge_SPARS = pd.read_sql(sql,conn)\n",
    "    discharge_SPARS.drop_duplicates(inplace=True)    \n",
    "    \n",
    "    logger.info(f\"Successfully queried tblNOMSAssessmentDetails for Discharges entered to SPARS.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to query tblNOMSAssessmentDetails for Discharges entered to SPARS.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8331a62",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Merges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b050fc1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Merge patient_details and encounters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40229e4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.014773Z",
     "start_time": "2023-08-08T14:57:03.006060Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    full_data_collection_df = patient_details_df.merge(encounter_df,\n",
    "                                                       on='PatientID',\n",
    "                                                       how='left')\n",
    "    # drop patients without encounters\n",
    "    full_data_collection_df = full_data_collection_df[full_data_collection_df['EncounterDate'].notna()]\n",
    "    \n",
    "    logger.info(f\"Successfully merged patient deatils with encounters.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to merge patient deatils with encounters.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b81ef8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Merge in Statuses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e053746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.027834Z",
     "start_time": "2023-08-08T14:57:03.016774Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    full_data_collection_df = full_data_collection_df.merge(discharged_patients_df,\n",
    "                                                            on = 'PatientID',\n",
    "                                                            how = 'left')\n",
    "    # fill nan status\n",
    "    full_data_collection_df['Status'].fillna('Active',inplace=True)\n",
    "    \n",
    "    logger.info(f\"Successfully merged in discharged patients.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to merge in discharged patients.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11304ff5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Merge in Baseline NOMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef02019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.039357Z",
     "start_time": "2023-08-08T14:57:03.030829Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    full_data_collection_df = full_data_collection_df.merge(baseline_df,\n",
    "                                                            on='PatientID',\n",
    "                                                            how='left')\n",
    "    full_data_collection_df['Baseline NOMS'].fillna(False,inplace=True)\n",
    "\n",
    "    logger.info(f\"Successfully merged in Baseline NOMS.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to merge in Baseline NOMS.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b078a1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Merge in Reassessment NOMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e764bce5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.050004Z",
     "start_time": "2023-08-08T14:57:03.042353Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    full_data_collection_df = full_data_collection_df.merge(reassessment_df,\n",
    "                                                            on='PatientID',\n",
    "                                                            how='left')\n",
    "    full_data_collection_df['6 Month Reassessment NOMS'].fillna(False,inplace=True)\n",
    "\n",
    "    logger.info(f\"Successfully merged in Reassessment NOMS.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to merge in Reassessment NOMS.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c519a79f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Merge in Discharge NOMS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e639d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.063009Z",
     "start_time": "2023-08-08T14:57:03.052002Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    full_data_collection_df = full_data_collection_df.merge(discharge_df,\n",
    "                                                            on='PatientID',\n",
    "                                                            how='left')\n",
    "    full_data_collection_df['Discharge NOMS'].fillna(False,inplace=True)\n",
    "\n",
    "    logger.info(f\"Successfully merged in Discharge NOMS.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to merge in Discharge NOMS.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f88bc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Merge in SPARS Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b7842c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.079331Z",
     "start_time": "2023-08-08T14:57:03.065008Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try: # add the baseline SPARS\n",
    "    full_data_collection_df = full_data_collection_df.merge(baseline_SPARS,\n",
    "                                                            on='PatientID',\n",
    "                                                            how='left')\n",
    "    logger.info(f\"Successfully merged in Baseline SPARS.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to merge in Baseline SPARS.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "    \n",
    "\n",
    "try: # add the reassessment SPARS\n",
    "    full_data_collection_df = full_data_collection_df.merge(reassessment_SPARS,\n",
    "                                                        on='PatientID',\n",
    "                                                        how='left')\n",
    "    logger.info(f\"Successfully merged in Reassessment SPARS.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to merge in Reassessment SPARS.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "try: # add the discharge SPARS\n",
    "    full_data_collection_df = full_data_collection_df.merge(discharge_SPARS,\n",
    "                                                        on='PatientID',\n",
    "                                                        how='left')\n",
    "    logger.info(f\"Successfully merged in Discharge SPARS.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to merge in Discharge SPARS.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "\n",
    "foo = full_data_collection_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6618acd4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Merge in New Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d855e5a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NoteSubTypeDict = {5: \"First Attempt\",\n",
    "                    6: 'First Attempt',\n",
    "                    7: \"First Attempt\"}\n",
    "NoteSubTypeColumnDict = {5: 'Baseline SPARS',\n",
    "                          6: \"Reassessment SPARS\",\n",
    "                          7: \"Discharge SPARS\"}\n",
    "try:\n",
    "    sql=f'''\n",
    "    SELECT \n",
    "        *\n",
    "    FROM \n",
    "        tblPatientNotes\n",
    "    WHERE\n",
    "        NoteSubType IN (5, 6, 7)\n",
    "    ORDER BY\n",
    "        PatientID\n",
    "    '''\n",
    "    patientNotes = pd.read_sql(sql,conn)\n",
    "    \n",
    "\n",
    "    \n",
    "    patientNotes['NoteAddedOn'] = pd.to_datetime(patientNotes['NoteAddedOn'])\n",
    "    patientNotes.sort_values(by='NoteAddedOn', ascending=False)\n",
    "    patientNotes['NoteSubTypeName'] = patientNotes['NoteSubType'].map(lambda subtypeID: NoteSubTypeDict[int(subtypeID)])\n",
    "    patientNotes['NoteSubTypeColumn'] = patientNotes['NoteSubType'].map(lambda subtypeID: NoteSubTypeColumnDict[int(subtypeID)])\n",
    "    patientNotesPivot = patientNotes.pivot(index=['PatientID'], columns = \"NoteSubTypeColumn\", values=\"NoteSubTypeName\").reset_index()\n",
    "    patientbaselineDict = patientNotesPivot.set_index('PatientID').to_dict()['Baseline SPARS']\n",
    "    patientReassessmentDict = patientNotesPivot.set_index('PatientID').to_dict()['Reassessment SPARS']\n",
    "    patientDischargeDict = patientNotesPivot.set_index('PatientID').to_dict()['Discharge SPARS']\n",
    "\n",
    "    def checkforBaselineNotes(patientID, note):\n",
    "        if note == \"\" or str(note) == 'nan':\n",
    "            return patientbaselineDict.get(patientID, \"\")\n",
    "        else:\n",
    "            return note\n",
    "\n",
    "    def checkforReassessmentNotes(patientID, note):\n",
    "        if note == \"\" or str(note) == 'nan':\n",
    "            return patientReassessmentDict.get(patientID, \"\")\n",
    "        else:\n",
    "            return note\n",
    "\n",
    "    def checkforDischargeNotes(patientID, note):\n",
    "        if note == \"\" or str(note) == 'nan':\n",
    "            return patientDischargeDict.get(patientID, \"\")\n",
    "        else:\n",
    "            return note\n",
    "    full_data_collection_df['Baseline SPARS'] = full_data_collection_df.apply(lambda row: checkforBaselineNotes(row['PatientID'], row['Baseline SPARS']), axis=1)\n",
    "    full_data_collection_df['Reassessment SPARS'] = full_data_collection_df.apply(lambda row: checkforReassessmentNotes(row['PatientID'], row['Reassessment SPARS']), axis=1)\n",
    "    full_data_collection_df['Discharge SPARS'] = full_data_collection_df.apply(lambda row: checkforDischargeNotes(row['PatientID'], row['Discharge SPARS']), axis=1)\n",
    "#     logger.info(f\"Successfully queried tblNotes and created columns.\")\n",
    "except Exception as e:\n",
    "#     logger.error(f\"Failed to query table notes and creat columns.\", exc_info=True) \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b36496",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41cf83cf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Prettify Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8a108",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.116253Z",
     "start_time": "2023-08-08T14:57:03.080333Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_data_collection_df = foo.copy()\n",
    "\n",
    "try: # Format Names\n",
    "    first_name = full_data_collection_df['FirstName'].map(lambda name: str(name).capitalize())\n",
    "    last_name = full_data_collection_df['LastName'].map(lambda name: str(name).capitalize())\n",
    "    full_data_collection_df['Name'] = last_name + ', ' + first_name\n",
    "    full_data_collection_df.drop(columns=['FirstName','LastName'], inplace=True)\n",
    "    \n",
    "    logger.info(f\"Successfully formated names.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to format names.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "    \n",
    "try: # Baseline Date\n",
    "    full_data_collection_df['Hour'] = pd.to_datetime(full_data_collection_df['Hour'])\n",
    "    full_data_collection_df['Baseline Due Date'] = full_data_collection_df['Hour'] + DateOffset(days=30)\n",
    "    full_data_collection_df['Baseline Due Date'] = full_data_collection_df['Baseline Due Date'].map(lambda num: num.strftime('%m-%d-%Y'))\n",
    "\n",
    "    logger.info(f\"Successfully added Baseline Due Date.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to add Baseline Due Date.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "    \n",
    "try:    # Baseline Warning\n",
    "    full_data_collection_df['Baseline Due Date'] = pd.to_datetime(full_data_collection_df['Baseline Due Date'])\n",
    "    full_data_collection_df['Baseline Warning'] = (full_data_collection_df['Baseline Due Date'] <= (pd.Timestamp.today())) & (full_data_collection_df['Baseline NOMS'] == False)\n",
    "    \n",
    "    logger.info(f\"Successfully added Baseline Warning.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to add Baseline Warning.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "    \n",
    "try:    # 6 Month Reassessment Date\n",
    "    full_data_collection_df['6 Month Reassessment Date'] = full_data_collection_df['Hour'] + DateOffset(months=6)\n",
    "    full_data_collection_df['6 Month Reassessment Date'] = full_data_collection_df['6 Month Reassessment Date'].map(lambda num: num.strftime('%m-%d-%Y'))\n",
    "\n",
    "    logger.info(f\"Successfully added Reassessment Date.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to add Reassessment Date.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "    \n",
    "try:    # 6 Month Warning\n",
    "    full_data_collection_df['6 Month Reassessment Date'] = pd.to_datetime(full_data_collection_df['6 Month Reassessment Date'])\n",
    "    full_data_collection_df['6 Month Reassessment Warning'] = full_data_collection_df['6 Month Reassessment Date'] - DateOffset(months=1) <= pd.Timestamp.today()\n",
    "\n",
    "    logger.info(f\"Successfully added Reassessment Warning.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to add Reassessment Warning.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "    \n",
    "try:    # add days since first encounter\n",
    "    today = datetime.date.today()\n",
    "    today = pd.to_datetime(today)\n",
    "    def daysSinceFirstEncounter(row):\n",
    "        date = row['EncounterDate']\n",
    "        if type(date) == pd.Timestamp:\n",
    "            return (today - date).days\n",
    "        return np.nan\n",
    "#     def daysTillBLineCompletion(row):\n",
    "#         encounter_date = row['EncounterDate']\n",
    "#         if isinstance(encounter_date, pd.Timestamp):\n",
    "            \n",
    "    def daysTillThirtyDaysAfter(row):\n",
    "        encounter_date = row['EncounterDate']\n",
    "        if isinstance(encounter_date, pd.Timestamp):\n",
    "            # Calculate thirty days after the encounter date\n",
    "            thirty_days_after = encounter_date + pd.DateOffset(days=30)\n",
    "            days_till_thirty_days_after = (thirty_days_after - pd.Timestamp.today()).days\n",
    "            return days_till_thirty_days_after\n",
    "        return np.nan\n",
    "    def daysTillSevenMonths(row):\n",
    "        encounter_date = row['EncounterDate']\n",
    "        if isinstance(encounter_date, pd.Timestamp):\n",
    "            # Calculate seven months from the encounter date\n",
    "            seven_months_later = encounter_date + pd.DateOffset(months=7)\n",
    "            # Calculate the number of days between today and seven months later\n",
    "            days_till_seven_months = (seven_months_later - pd.Timestamp.today()).days\n",
    "            return days_till_seven_months\n",
    "        return np.nan\n",
    "    full_data_collection_df['Days Since Encounter'] = full_data_collection_df.apply(lambda row: daysSinceFirstEncounter(row), axis=1)  \n",
    "    full_data_collection_df['Days Till Reassessment Date'] = full_data_collection_df.apply(lambda row: daysTillSevenMonths(row), axis=1)  \n",
    "    full_data_collection_df['Days Till Baseline Date'] = full_data_collection_df.apply(lambda row: daysTillThirtyDaysAfter(row), axis=1)  \n",
    "    logger.info(f\"Successfully added Days Since First Encounter and days remaining till baseline/reassessment due dates.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to add Days Since First Encounter and days remaining till baseline/reassessment due dates.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)\n",
    "\n",
    "try:    # add days since final encounter\n",
    "    def daysSinceDischarge(row):\n",
    "        date = row['Final Encounter']\n",
    "        if type(date) == pd.Timestamp:\n",
    "            return (today - date).days\n",
    "        return np.nan\n",
    "    full_data_collection_df['Days Since Final Encounter'] = full_data_collection_df.apply(lambda row: daysSinceDischarge(row), axis=1)\n",
    "\n",
    "    logger.info(f\"Successfully added Days Since Final Encounter.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to add Days Since Final Encounter.\", exc_info=True) \n",
    "    print(e)\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdde660",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.122045Z",
     "start_time": "2023-08-08T14:57:03.118263Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_data_collection_df[full_data_collection_df['PatientID'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda910fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.131505Z",
     "start_time": "2023-08-08T14:57:03.125040Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Reorder Columns\n",
    "full_data_collection_df = full_data_collection_df[['PatientID',\n",
    "                                                   'Name',\n",
    "                                                   'DOB',\n",
    "                                                   'Phone',\n",
    "                                                   'MRNNumber',\n",
    "                                                   'Status',\n",
    "                                                   'EncounterDate',\n",
    "                                                   'Hour',\n",
    "                                                   'Days Since Encounter',\n",
    "                                                   'Days Till Reassessment Date',\n",
    "                                                   'Days Till Baseline Date',\n",
    "                                                   'Baseline NOMS',\n",
    "                                                   'Baseline Due Date',\n",
    "                                                   'Baseline Warning',\n",
    "                                                   'Baseline SPARS',\n",
    "                                                   '6 Month Reassessment NOMS',\n",
    "                                                   '6 Month Reassessment Date',\n",
    "                                                   '6 Month Reassessment Warning',\n",
    "                                                   'Reassessment SPARS',\n",
    "                                                   'Final Encounter',\n",
    "                                                   'Days Since Final Encounter',\n",
    "                                                   'Discharge NOMS',\n",
    "                                                   'Discharge SPARS']]\n",
    "full_data_collection_df.drop_duplicates('PatientID', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b262565",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Push to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde36c82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.137364Z",
     "start_time": "2023-08-08T14:57:03.134501Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with pd.ExcelWriter(r\"../data/NOMS Survey Completion.xlsx\") as writer: \n",
    "#     full_data_collection_df.to_excel(writer, sheet_name=\"Patient Data\",index = False)\n",
    "#     consent_df.to_excel(writer, sheet_name=\"Consent Data\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e4d841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.141960Z",
     "start_time": "2023-08-08T14:57:03.138365Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \", \".join([item + \" \" + str(full_data_collection_df[item].dtype) for item in full_data_collection_df.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29182280",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### push full_data_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfcddf6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.181493Z",
     "start_time": "2023-08-08T14:57:03.143958Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_name = \"ptNOMS_Completion\"\n",
    "try:\n",
    "    c = conn.cursor()\n",
    "    c.execute(f'''CREATE TABLE IF NOT EXISTS {table_name} (PatientID INTEGER,\n",
    "                                                           Name TEXT,\n",
    "                                                           DOB TEXT,\n",
    "                                                           Phone, TEXT\n",
    "                                                           MRNNumber TEXT,\n",
    "                                                           Status TEXT,\n",
    "                                                           EncounterDate TEXT,\n",
    "                                                           Hour TEXT,\n",
    "                                                           DaysSinceEncounter INTEGER,\n",
    "                                                           DaysTillBaseline INTEGER,\n",
    "                                                           DaysTillReassessment INTEGER\n",
    "                                                           BaselineNOMS TEXT,\n",
    "                                                           BaselineDueDate TEXT,\n",
    "                                                           BaselineWarning TEXT,\n",
    "                                                           Baseline SPARS TEXT,\n",
    "                                                           _6MonthReassessmentNOMS TEXT,\n",
    "                                                           _6MonthReassessmentDate TEXT,\n",
    "                                                           _6MonthReassessmentWarning TEXT,\n",
    "                                                           ReassessmentSPARS TEXT,\n",
    "                                                           FinalEncounter TEXT,\n",
    "                                                           DaysSinceFinalEncounter INTEGER,\n",
    "                                                           DischargeNOMS TEXT,\n",
    "                                                           DischargeSPARS TEXT)''')\n",
    "    conn.commit()\n",
    "    logger.info(f\"Successfully created {table_name}.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to create {table_name}.\", exc_info=True) \n",
    "    print(e)\n",
    "    \n",
    "try:\n",
    "    full_data_collection_df.to_sql(table_name, conn, if_exists='replace', index = False)\n",
    "    logger.info(f\"Successfully pushed data to {table_name}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to push data to {table_name}.\", exc_info=True) \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2321acf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Push consent_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc32ab6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.186393Z",
     "start_time": "2023-08-08T14:57:03.182494Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \", \".join([item + \" \" + str(consent_df[item].dtype) for item in consent_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95be822",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.211904Z",
     "start_time": "2023-08-08T14:57:03.189388Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_name = \"ptNOMS_Consent\"\n",
    "try:\n",
    "    c = conn.cursor()\n",
    "    c.execute(f'''CREATE TABLE IF NOT EXISTS {table_name} (PatientID INTEGER,\n",
    "                                                           Consent TEXT,\n",
    "                                                           Reason TEXT)''')\n",
    "    conn.commit()\n",
    "    logger.info(f\"Successfully created {table_name}.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to create {table_name}.\", exc_info=True) \n",
    "    print(e)\n",
    "    \n",
    "try:\n",
    "    consent_df.to_sql(table_name, conn, if_exists='replace', index = False)\n",
    "    logger.info(f\"Successfully pushed data to {table_name}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to push data to {table_name}.\", exc_info=True) \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b333663",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-08T14:57:03.216874Z",
     "start_time": "2023-08-08T14:57:03.212905Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "NOMS-Survey Completion.ipynb",
   "output_path": "snapshots/NOMS-Survey Completion.ipynb",
   "parameters": {},
   "start_time": "2024-03-06T12:01:20.199939",
   "version": "2.4.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "67px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.297px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "499.56px",
    "left": "35.9744px",
    "right": "20px",
    "top": "144.972px",
    "width": "471.449px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}