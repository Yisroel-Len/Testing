{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdbee8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T18:50:53.692673Z",
     "start_time": "2024-09-17T18:50:52.832158Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "# from datetime import datetime\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760a2fc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T19:14:29.325156Z",
     "start_time": "2024-09-17T19:14:29.317644Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "path = r\"..\\..\\Logs\\clinical_log.log\"\n",
    "logging.basicConfig(filename=path,\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s,%(msecs)d,%(name)s,%(levelname)s,%(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.DEBUG)\n",
    "logger = logging.getLogger(\"WorkedOnClaims\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a8cd7d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T18:50:54.268540Z",
     "start_time": "2024-09-17T18:50:53.707812Z"
    }
   },
   "outputs": [],
   "source": [
    "conn = create_engine(r'mssql+pyodbc://@PYTHONSERVER\\SQLEXPRESS/InSync?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes', fast_executemany=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7f5158-4ba5-480f-bf49-c7fca8943011",
   "metadata": {},
   "source": [
    "# To do\n",
    "Need to fix merge so that it uses a combination of claim number and line-item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71e1ace9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T18:51:12.430247Z",
     "start_time": "2024-09-17T18:50:54.272285Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    logger.info(\"Creating a dataframe from tblPayment table as well as other tables \")\n",
    "    sql = '''\n",
    "    SELECT\n",
    "        ClaimNo,\n",
    "        tblPayment.CreatedOn,\n",
    "        tblPayment.CreatedBy,\n",
    "        tblResourceDetails1.FullName,\n",
    "        DOSFrom\n",
    "    FROM \n",
    "        tblPayment\n",
    "        LEFT JOIN tblChargeDetails ON (tblChargeDetails.ChargeID=tblPayment.ClaimNo)\n",
    "        LEFT JOIN tblUser ON (tblPayment.CreatedBy=tblUser.UserID)\n",
    "        LEFT JOIN \n",
    "        (SELECT   \n",
    "            DISTINCT(UserID), \n",
    "            FullName\n",
    "        FROM \n",
    "            tblResourceDetails) \n",
    "        tblResourceDetails1 ON (tblUser.Userid=tblResourceDetails1.Userid)\n",
    "    '''\n",
    "    payment_df = pd.read_sql(sql, conn)\n",
    "    logger.info(\"Successfully created a dataframe from tblPayment table\")\n",
    "    payment_df['CreatedOn'] = pd.to_datetime(payment_df['CreatedOn'])\n",
    "    payment_df['DOSFrom'] = pd.to_datetime(payment_df['DOSFrom'])\n",
    "    # in order to merge the payment and submissions dataframes on the claimNo, we need to make sure they're sorted the same \n",
    "    # otherwise createdon dates and submission dates won't match up \n",
    "    payment_df = payment_df.sort_values(by=['ClaimNo', 'CreatedOn'], ascending=[True, False])\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    logger.error(\"Failed to create a dataframe from tblPayment table\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b74afcc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T18:51:15.565408Z",
     "start_time": "2024-09-17T18:51:12.437501Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ylen\\AppData\\Local\\Temp\\3\\ipykernel_12408\\4281278560.py:12: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  submissions['SubmissionDate'] = pd.to_datetime(submissions['SubmissionDate'])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logger.info(\"Creating a dataframe from tblClaimSubmission\")\n",
    "    sql = '''\n",
    "    SELECT\n",
    "        ClaimNumber as ClaimNo,\n",
    "        SubmissionDate\n",
    "    FROM \n",
    "        tblClaimSubmission\n",
    "    '''\n",
    "    submissions = pd.read_sql(sql, conn)\n",
    "    logger.info(\"Successfully created a dataframe from tblClaimSubmission\")\n",
    "    submissions['SubmissionDate'] = pd.to_datetime(submissions['SubmissionDate'])\n",
    "    # in order to merge the payment and submissions dataframes on the claimNo, we need to make sure they're sorted the same \n",
    "    # otherwise createdon dates and submission dates won't match up \n",
    "    submissions = submissions.sort_values(by=['ClaimNo', 'SubmissionDate'], ascending=[True, False])\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    logger.error(\"Failed to create a dataframe from tblClaimSubmission table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73332894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T18:51:16.263141Z",
     "start_time": "2024-09-17T18:51:15.568413Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    logger.info(\"Merging payment_df and submissions dataframes\")\n",
    "    payment_df = payment_df.merge(submissions, how='left', on='ClaimNo', validate='m:m')\n",
    "    logger.info(\"Successfully merged payment_df and submissions dataframes\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    logger.error(\"Failed to merge payment_df and submissions dataframes\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6a773c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T18:51:25.703917Z",
     "start_time": "2024-09-17T18:51:16.265267Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    logger.info(\"Creating a dataframe from tblPaymentDetails table and tblPaymentTransactionTypes table\")\n",
    "    sql = '''\n",
    "    SELECT\n",
    "        ClaimNo,\n",
    "        DisplayName as HadDenial\n",
    "    FROM \n",
    "        tblPaymentDetails\n",
    "        LEFT JOIN tblPaymentTransactionTypes ON (tblPaymentDetails.TransactionType=tblPaymentTransactionTypes.TransactionType)\n",
    "    WHERE \n",
    "        DisplayName = 'Denial'\n",
    "    '''\n",
    "    denials = pd.read_sql(sql, conn)\n",
    "    logger.info(\"Successfully created a dataframe from tblPaymentDetails table and tblPaymentTransactionTypes table\")\n",
    "    denials = denials.drop_duplicates('ClaimNo')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    logger.error(\"Failed to create a dataframe from tblPaymentDetails table and tblPaymentTransactionTypes table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e70314fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T18:51:25.901455Z",
     "start_time": "2024-09-17T18:51:25.711076Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    logger.info(\"Filtering payment_df for payments that have a denial\")\n",
    "    # did payment have a denial\n",
    "    payment_df = payment_df[payment_df[\"ClaimNo\"].isin(denials['ClaimNo'])].copy()\n",
    "    logger.info(\"Successfully filtered payment_df for payments that have a denial\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    logger.error(\"Failed to filter payment_df for payments that have a denial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b91f31c",
   "metadata": {},
   "source": [
    "The below code could be improved with a groupby statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9d25a36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T18:51:26.028811Z",
     "start_time": "2024-09-17T18:51:25.904479Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Filtering payment_df for payments that have a denial\n",
    "    # Denials that werenâ€™t worked on have a submission date prior to their most recent entered on date and the created by user is not the system (user id -99)\n",
    "    payment_df.sort_values(by='SubmissionDate', inplace=True, ascending=False)\n",
    "    # Most recent Entered On \n",
    "    mostRecentPayment = payment_df.drop_duplicates(\"ClaimNo\", keep='first').copy()\n",
    "    mostRecentPayment['WorkedOn'] = (mostRecentPayment['SubmissionDate'] > mostRecentPayment['CreatedOn']) & (mostRecentPayment['CreatedBy'] != -99)\n",
    "    # mostRecentPayment['WorkedOn'] = mostRecentPayment.apply(lambda row: False if row['CreatedBy'] == -99 else row['WorkedOn'], axis=1)\n",
    "    logger.info(\"Successfully filtered payment_df for payments that have a denial\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    logger.error(\"Failed to Filter payment_df for payments that have a denial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "994afa7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-17T18:51:26.041110Z",
     "start_time": "2024-09-17T18:51:26.033376Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    logger.info(\"Creating a new column NeedsWork for claims that need to be worked on\")\n",
    "    # They need to be worked on if they haven't yet been worked on. So \"needs to be\" is the inverse of WorkedOn\n",
    "    logger.info(\"Successfully created a new column NeedsWork for claims that need to be worked on\")\n",
    "    mostRecentPayment['NeedsWork'] = ~mostRecentPayment['WorkedOn']\n",
    "except Exception as e:\n",
    "    print(e)    \n",
    "    logger.error(\"Failed to create a new column NeedsWork for claims that need to be worked on\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ec46ffe-293e-47ca-9fb9-2ac9b763e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    logger.info(\"Adding/replacing columns in ptWorkedOnDenials with columns from workedOnDF dataframe\")\n",
    "    workedOnDf = mostRecentPayment[['ClaimNo', 'NeedsWork']].copy()\n",
    "    workedOnDf['NeedsWork'] = workedOnDf['NeedsWork'].astype(str)\n",
    "    workedOnDf['ClaimNo'] = workedOnDf['ClaimNo'].astype(str)\n",
    "    workedOnDf.to_sql(\"ptWorkedOnDenials\",conn, if_exists=\"replace\", index=False)\n",
    "    logger.info(\"Success in Adding/replacing columns in ptWorkedOnDenials with columns from workedOnDF dataframe\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    logger.error(\"Failed in Adding/replacing columns in ptWorkedOnDenials with columns from workedOnDF dataframe\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
